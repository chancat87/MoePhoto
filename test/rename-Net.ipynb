{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i rename.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AiLUT import AiLUT\n",
    "models = [\n",
    "  (AiLUT, {}, 'state_dict', '../model/AiLUT/AiLUT-FiveK-sRGB.pth'),\n",
    "  (AiLUT, {}, 'state_dict', '../model/AiLUT/AiLUT-FiveK-XYZ.pth'),\n",
    "  (AiLUT, dict(n_ranks=5, backbone='res18'), 'state_dict', '../model/AiLUT/AiLUT-PPR10KA-sRGB.pth')\n",
    "]\n",
    "rsts = [\n",
    "    # match, replace, with, suffix, insert\n",
    "    (('',), 'backbone.net.', 'backbone.', None, None),\n",
    "]\n",
    "subs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NAFNet import NAFNet\n",
    "layers = 4\n",
    "models = [\n",
    "  (NAFNet, dict(width=32, enc_blk_nums=[1, 1, 1, 28], dec_blk_nums=[1, 1, 1, 1]), 'params', '../model/NAFNet/NAFNet-GoPro-width32.pth'),\n",
    "  (NAFNet, dict(width=64, enc_blk_nums=[1, 1, 1, 28], dec_blk_nums=[1, 1, 1, 1]), 'params', '../model/NAFNet/NAFNet-GoPro-width64.pth'),\n",
    "  (NAFNet, dict(width=64, enc_blk_nums=[1, 1, 1, 28], dec_blk_nums=[1, 1, 1, 1]), 'params', '../model/NAFNet/NAFNet-REDS-width64.pth'),\n",
    "  (NAFNet, dict(width=32, enc_blk_nums=[2, 2, 4, 8], middle_blk_num=12, dec_blk_nums=[2, 2, 2, 2]), 'params', '../model/NAFNet/NAFNet-SIDD-width32.pth'),\n",
    "  (NAFNet, dict(width=64, enc_blk_nums=[2, 2, 4, 8], middle_blk_num=12, dec_blk_nums=[2, 2, 2, 2]), 'params', '../model/NAFNet/NAFNet-SIDD-width64.pth')\n",
    "]\n",
    "rsts = [\n",
    "    # match, replace, with, suffix, insert\n",
    "    (('',), 'middle_blks', 'layers.{}'.format(layers), None, None),\n",
    "]\n",
    "subs = [\n",
    "    # match, replace, with, suffix, insert\n",
    "    (re.compile(r'encoders\\.([\\d]+\\.)(.*)'), r'layers.\\1encoder.\\2'),\n",
    "    (re.compile(r'downs\\.([\\d]+\\.)(.*)'), r'layers.\\1down.\\2'),\n",
    "    (re.compile(r'ups\\.([\\d]+)\\.(.*)'), lambda m: ''.join(('layers.', str(layers - 1 - int(m[1])), '.up.', m[2]))),\n",
    "    (re.compile(r'decoders\\.([\\d]+)\\.(.*)'), lambda m: ''.join(('layers.', str(layers - 1 - int(m[1])), '.decoder.', m[2])))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videoSR import BasicVSRPlusPlus as modules\n",
    "models = [\n",
    "  (None, {}, 'state_dict', '../model/vsr/basicvsr_plusplus_c128n25_ntire_decompress_track2_20210314-eeae05e6.pth')\n",
    "  (None, {}, 'state_dict', '../model/vsr/basicvsr_plusplus_c128n25_ntire_vsr_20210311-1ff35292.pth'),\n",
    "  (None, {}, 'state_dict', '../model/vsr/basicvsr_plusplus_c64n7_8x1_300k_vimeo90k_bd_20210305-ab315ab1.pth')\n",
    "]\n",
    "rsts = [\n",
    "    # match, replace, with, suffix, insert\n",
    "    (('',), 'step_counter', '', None, None),\n",
    "    (('',), 'generator.', '', None, None),\n",
    "]\n",
    "subs = [\n",
    "    # match, replace, with, suffix, insert\n",
    "    (re.compile(r'(spynet\\.basic_module\\.[\\d]+\\.)basic_module\\.(.*)'), r'\\1\\2'),\n",
    "    (re.compile(r'upconv1\\.(.*)'), r'upsample.0.\\1'),\n",
    "    (re.compile(r'upconv2\\.(.*)'), r'upsample.3.\\1'),\n",
    "    (re.compile(r'conv_hr\\.(.*)'), r'upsample.6.\\1'),\n",
    "    (re.compile(r'conv_last\\.(.*)'), r'upsample.8.\\1')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DLN import DLN\n",
    "models = [\n",
    "    (DLN, {}, 0, '../model/DLN/DLN_finetune_LOL.pth')\n",
    "]\n",
    "rsts = [\n",
    "    (('',), 'module.', '', None, None)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Net2x, Net3x, Net4x, NetDN\n",
    "models = [\n",
    "    # model Class, kwargs, root, *paths\n",
    "    (Net2x, {}, 0, '../model/a2/model_new.pth', '../model/p2/model_new.pth'),\n",
    "    (Net3x, {}, 0, '../model/a3/model_new.pth', '../model/p3/model_new.pth'),\n",
    "    (Net4x, {}, 0, '../model/a4/model_new.pth', '../model/p4/model_new.pth'),\n",
    "    (NetDN, {}, 0, '../model/dn_lite5/model_new.pth', '../model/dn_lite10/model_new.pth', '../model/dn_lite15/model_new.pth')\n",
    "]\n",
    "rsts = [\n",
    "    # match, replace, with, suffix, insert\n",
    "    ((r'convt_F.\\.',), None, None, '', '0.')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import RRDBNet\n",
    "models = [\n",
    "    (RRDBNet, {'num_in_ch': 3, 'num_out_ch': 3, 'scale': 2}, 'params_ema', '../model/gan/RealESRGAN_x2plus.pth'),\n",
    "    (RRDBNet, {'num_in_ch': 3, 'num_out_ch': 3}, 'params_ema', '../model/gan/RealESRGAN_x4plus.pth'),\n",
    "    (RRDBNet, {'num_in_ch': 3, 'num_out_ch': 3, 'num_block': 6}, 'params_ema', '../model/gan/RealESRGAN_x4plus_anime_6B.pth')\n",
    "]\n",
    "subs = [\n",
    "    (re.compile(r'(body.[\\d]+.rdb[\\d]+.)conv([\\d]+)(\\..*)'), lambda m: ''.join((m[1], 'conv.', str(int(m[2]) - 1), m[3])))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videoSR import modules\n",
    "models = [\n",
    "  (None, {}, 'params', '../model/vsr/IconVSR_Vimeo90K_BDx4-cfcb7e00.pth')\n",
    "]\n",
    "rsts = [\n",
    "    # match, replace, with, suffix, insert\n",
    "    ((r'[^\\.]+_trunk\\.',), 'main.', '', None, None),\n",
    "]\n",
    "subs = [\n",
    "    # match, replace, with, suffix, insert\n",
    "    (re.compile(r'(spynet\\.basic_module\\.[\\d]+\\.)basic_module\\.(.*)'), r'\\1\\2'),\n",
    "    (re.compile(r'upconv1\\.(.*)'), r'upsample.0.\\1'),\n",
    "    (re.compile(r'upconv2\\.(.*)'), r'upsample.3.\\1'),\n",
    "    (re.compile(r'conv_hr\\.(.*)'), r'upsample.6.\\1'),\n",
    "    (re.compile(r'conv_last\\.(.*)'), r'upsample.8.\\1')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ESTRNN import modules\n",
    "\n",
    "models = [\n",
    "  # model Class, kwargs, root, *paths\n",
    "  (None, {}, 'state_dict', '../model/ESTRNN/ESTRNN_C80B15_BSD_1ms8ms.tar', '../model/ESTRNN/ESTRNN_C80B15_BSD_2ms16ms.tar', '../model/ESTRNN/ESTRNN_C80B15_BSD_3ms24ms.tar')\n",
    "]\n",
    "rsts = [\n",
    "  # match, replace, with, suffix, insert\n",
    "  (('',), 'module.model.', '', None, None),\n",
    "  (('recons.',), 'model.', '', None, None)\n",
    "]\n",
    "subs = [\n",
    "  (re.compile(r'(.+\\..+\\..+)\\.conv1x1(\\..*)'), r'\\1.3\\2'),\n",
    "  (re.compile(r'(.+\\.)dense_layers\\.(.*)'), r'\\1\\2'),\n",
    "  (re.compile(r'(cell\\.F_B[\\d]+)\\.rdb(\\..*)'), r'\\1.0\\2'),\n",
    "  (re.compile(r'(cell\\.F_B[\\d]+)\\.down_sampling(\\..*)'), r'\\1.1\\2')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IFRNet import modules, getOpt\n",
    "\n",
    "models = [\n",
    "  # model Class, kwargs, root, *paths\n",
    "  (None, {}, None, '../model/IFRNet/IFRNet_S_Vimeo90K.pth', '../model/IFRNet/IFRNet_Vimeo90K.pth', '../model/IFRNet/IFRNet_L_Vimeo90K.pth')\n",
    "]\n",
    "rsts = [\n",
    "  ((r'decoder[\\d]+\\.',), 'convblock.', '', None, None)\n",
    "]\n",
    "subs = [\n",
    "  (re.compile(r'encoder\\.pyramid([\\d]+)\\.'), lambda m: 'encoder.pyramids.{}.'.format(int(m[1]) - 1)),\n",
    "  (re.compile(r'decoder([\\d]+)\\.'), lambda m: 'decoder.decoders.{}.'.format(4 - int(m[1])))\n",
    "]\n",
    "options = [\n",
    "  {'model': 'S', 'sf': 2},\n",
    "  {'model': 'M', 'sf': 2},\n",
    "  {'model': 'L', 'sf': 2}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MPRNet import MPRNet\n",
    "models = [\n",
    "    # model Class, kwargs, root, *paths\n",
    "    (MPRNet, dict(n_feat=96, scale_unetfeats=48, scale_orsnetfeats=32), 'state_dict', '../model/MPRNet/model_deblurring.pth'),\n",
    "    (MPRNet, dict(n_feat=80, scale_unetfeats=48, scale_orsnetfeats=32), 'state_dict', '../model/MPRNet/model_denoising.pth'),\n",
    "    (MPRNet, dict(n_feat=40, scale_unetfeats=20, scale_orsnetfeats=16), 'state_dict', '../model/MPRNet/model_deraining.pth')\n",
    "]\n",
    "rsts = [\n",
    "    ((r'(.+\\.)body\\.',), 'body.', '', None, None),\n",
    "    ((r'(.+\\.)CA\\.',), 'CA.', '3.', None, None),\n",
    "]\n",
    "sm1 = lambda s: str(int(s) - 1)\n",
    "subs = [\n",
    "    (re.compile(r'shallow_feat([\\d]+)(\\..*)'), lambda m: ''.join(('shallow_feat.', sm1(m[1]), m[2]))),\n",
    "    (re.compile(r'(sam|concat)([\\d])[\\d](\\..*)'), lambda m: ''.join((m[1], '.', sm1(m[2]), m[3]))),\n",
    "    (re.compile(r'stage3_orsnet\\.orb([\\d]+)(\\..*)'), lambda m: ''.join(('stage3_orsnet.orb.', sm1(m[1]), m[2]))),\n",
    "    (re.compile(r'stage3_orsnet\\.up_(enc|dec)1\\.up(\\..*)'), lambda m: ''.join(('stage3_orsnet.conv_', m[1], '.1.0', m[2]))),\n",
    "    (re.compile(r'stage3_orsnet\\.up_(enc|dec)([\\d]+)\\.([\\d]+)\\.up(\\..*)'), lambda m: ''.join(('stage3_orsnet.conv_', m[1], '.', m[2], '.', m[3], m[4]))),\n",
    "    (re.compile(r'stage3_orsnet\\.conv_(enc|dec)([\\d]+)(\\..*)'), lambda m: ''.join(('stage3_orsnet.conv_', m[1], '.', sm1(m[2]), '.', sm1(m[2]), m[3]))),\n",
    "    (re.compile(r'stage3_orsnet\\.(.*)'), r'encoder.2.\\1'),\n",
    "    (re.compile(r'(stage[\\d]+_encoder\\.encoder_level[\\d]+\\.)([\\d]+)(\\..*)'), lambda m: ''.join((m[1], str(int(m[2]) + 1), m[3]))),\n",
    "    (re.compile(r'stage([\\d]+)_(encoder|decoder)\\.(encoder|decoder)_level([\\d]+)(\\..*)'), lambda m: ''.join((m[2], '.', sm1(m[1]), '.', m[3], '.', sm1(m[4]), m[5]))),\n",
    "    (re.compile(r'stage([\\d]+)_encoder\\.down([\\d])[\\d]\\.down(\\..*)'), lambda m: ''.join(('encoder.', sm1(m[1]), '.encoder.', m[2], '.0', m[3]))),\n",
    "    (re.compile(r'stage([\\d]+)_encoder\\.(csff_enc|csff_dec)([\\d]+)(\\..*)'), lambda m: ''.join(('encoder.', sm1(m[1]), '.', m[2], '.', sm1(m[3]), m[4]))),\n",
    "    (re.compile(r'([^\\.]+\\.)skip_attn([\\d]+)(\\..*)'), lambda m: ''.join((m[1], 'skip_attn.', sm1(m[2]), m[3]))),\n",
    "    (re.compile(r'(stage[\\d]+_decoder\\.up)[\\d]([\\d])(\\..*)'), lambda m: ''.join((m[1], '.', sm1(m[2]), m[3]))),\n",
    "    (re.compile(r'stage([\\d])_(encoder|decoder)(\\..*)'), lambda m: ''.join((m[2], '.', sm1(m[1]), m[3])))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = renameByRules(models, rsts=rsts, subs=subs, rules=[o['weight'] for o in modules.values()] if modules else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load('./RealBasicVSR_x4.pth')['state_dict']\n",
    "state = {}\n",
    "for key in getRoot(m, 'generator.image_cleaning.'):\n",
    "  newKey = key[len(r):]\n",
    "  state[newKey] = m[key]\n",
    "cc(state, getSubNames)([('0.main.', '0.')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "os.chdir(osp.join(osp.dirname(osp.abspath(__file__)), '../'))\n",
    "for option in options:\n",
    "  print(option)\n",
    "  getOpt(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(m)\n",
    "\n",
    "for key, o in modules.items():\n",
    "  m1 = o['f']()\n",
    "  print(key, m1.load_state_dict(m[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import conv2d311, ResidualBlockNoBN, make_layer\n",
    "from torch.nn import Sequential, LeakyReLU\n",
    "\n",
    "ResidualBlocksWithInputConv = lambda in_channels, out_channels=64, num_blocks=30: Sequential(\n",
    "  conv2d311(in_channels, out_channels),\n",
    "  LeakyReLU(negative_slope=0.1, inplace=True),\n",
    "  make_layer(ResidualBlockNoBN, num_blocks, num_feat=out_channels)\n",
    ")\n",
    "ImageCleaning = lambda num_feat=64, num_cleaning_blocks=20: Sequential(\n",
    "  ResidualBlocksWithInputConv(3, num_feat, num_cleaning_blocks),\n",
    "  conv2d311(num_feat, 3)\n",
    ")\n",
    "m = ImageCleaning()\n",
    "m.load_state_dict(state)\n",
    "torch.save(m.state_dict(), '../model/vsr/RealBasicVSR_ImageCleaning.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = models[-1][-1] + '.new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = models[-1][-1]\n",
    "m = models[-1][0](**models[-1][1])\n",
    "m.load_state_dict(torch.load(modelPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in m.parameters():\n",
    "  param.requires_grad_(False)\n",
    "m = castModel(m.eval())\n",
    "opt = Option(modelPath)\n",
    "opt.scale = 1\n",
    "opt.padding = 5\n",
    "opt.align = 16\n",
    "opt.ramCoef = 1 / 1.\n",
    "opt.squeeze = lambda x: x.squeeze(0)\n",
    "opt.unsqueeze = lambda x: x.unsqueeze(0)\n",
    "opt.modelCached = m\n",
    "modelPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = readPic('./blur.png')\n",
    "show(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ensemble(opt)(original)\n",
    "show(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity, schedule\n",
    "N = 41\n",
    "with profile(\n",
    "  activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "  schedule=schedule(wait=2, warmup=9, active=30, repeat=1)) as p:\n",
    "  for iter in range(N):\n",
    "    # y = m1(x)\n",
    "    p.step()\n",
    "  print(p.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=-1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec988e9570e5c851985c453e1f4c0a3f4576c4ac3bfa2d87d574a812d35a4363"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('py3.9': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
